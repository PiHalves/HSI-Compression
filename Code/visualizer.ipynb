{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.histogram import hsi_to_rgb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00bde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./results/lineRWKV_2026_01_14-00_33_25/logs/training_history.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a883611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model_path\n",
    "if not os.path.exists(model_history):\n",
    "    print(f\"Model history file {model_history} does not exist.\")\n",
    "    raise FileNotFoundError(f\"Model history file {model_history} does not exist.\")\n",
    "\n",
    "history = {}\n",
    "with open(model_history, \"r\") as f:\n",
    "    history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6854d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history:\n",
    "    plt.plot(history[key], label=key)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(f\"{key} over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = {}\n",
    "for key in history:\n",
    "    if key == \"epoch_times\":\n",
    "        continue\n",
    "    if key.split(\"_\")[1] not in data_sorted:\n",
    "        data_sorted[key.split(\"_\")[1]] = {}\n",
    "    if key.startswith(\"val\"):\n",
    "        data_sorted[key.split(\"_\")[1]][\"val\"] = history[key]\n",
    "    else:\n",
    "        data_sorted[key.split(\"_\")[1]][\"train\"] = history[key]\n",
    "\n",
    "translation_dict = {\n",
    "    \"loss\": \"Loss _0\",\n",
    "    \"acc\": \"Accuracy _1\",\n",
    "    \"sa\": \"SA _5\",\n",
    "    \"psnr\": \"PSNR _6\",\n",
    "    \"ssim\": \"SSIM _4\",\n",
    "    \"mse\": \"MSE _1\",\n",
    "    \"mae\": \"MAE _2\",\n",
    "    \"rmse\": \"RMSE _3\",\n",
    "}\n",
    "\n",
    "def sorting_key_func(key):\n",
    "    if key in translation_dict:\n",
    "        if key == \"loss\":\n",
    "            return 0\n",
    "        else:\n",
    "            return int(translation_dict[key.split].split(\"_\")[1])\n",
    "\n",
    "    return len(translation_dict) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e30e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data to paste into latex tikzpicture graph\n",
    "\n",
    "template = \"\"\"\n",
    "\\\\begin{figure}\n",
    "\\\\centering\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for idx, key in enumerate(sorted(data_sorted.keys(), key=lambda x: x.lower())):\n",
    "    if key not in translation_dict:\n",
    "        continue\n",
    "    subfig = f\"\"\"\n",
    "    \\\\begin{{subfigure}}{{0.4\\\\textwidth}}\n",
    "        \\\\centering\n",
    "        \\\\begin{{tikzpicture}}\n",
    "            \\\\begin{{axis}}[\n",
    "                    xlabel={{Training Epoch}},\n",
    "                    ylabel={{Value}},\n",
    "                    title={{{translation_dict[key]} over Epochs}},\n",
    "                    grid=major,\n",
    "                    y tick label style={{\n",
    "                            /pgf/number format/.cd,\n",
    "                            fixed,\n",
    "                            fixed zerofill,\n",
    "                            precision=2,\n",
    "                            /tikz/.cd\n",
    "                        }},\n",
    "                    x tick label style={{\n",
    "                            /pgf/number format/.cd,\n",
    "                            fixed,\n",
    "                            fixed zerofill,\n",
    "                            precision=0,\n",
    "                            /tikz/.cd\n",
    "                        }}\n",
    "                ]\n",
    "    \"\"\"\n",
    "    data = data_sorted[key][\"val\"]\n",
    "    formatted_data_val = \"\\n \".join([f\"({i}, {v})\" for i, v in enumerate(data)])\n",
    "    subfig += f\"\"\"\n",
    "        \\\\addplot [color=blue, mark=o] coordinates {{\n",
    "            {formatted_data_val}\n",
    "        }};\n",
    "        \\\\addlegendentry{{Validation}}\n",
    "    \"\"\"\n",
    "    data = data_sorted[key][\"train\"]\n",
    "    formatted_data_train = \"\\n \".join([f\"({i}, {v})\"\n",
    "    for i, v in enumerate(data)])\n",
    "    subfig += f\"\"\"\n",
    "        \\\\addplot [color=orange, mark=x] coordinates {{\n",
    "            {formatted_data_train}\n",
    "        }};\n",
    "        \\\\addlegendentry{{Training}}\n",
    "    \n",
    "        \\\\end{{axis}}\n",
    "        \\\\end{{tikzpicture}}\n",
    "        \\\\caption{{CHANGE ME!!!}}\n",
    "        \\\\label{{fig:{key}}}\n",
    "    \\\\end{{subfigure}}\n",
    "    \\\\hfill\n",
    "    \"\"\"\n",
    "    template += subfig\n",
    "template += \"\"\"\n",
    "\\\\caption{Training and Validation Metrics over Epochs}\n",
    "\\\\label{fig:training_metrics}\n",
    "\\\\end{figure}\n",
    "\"\"\"\n",
    "\n",
    "print(template)\n",
    "\n",
    "    # print(f\"{key} data for TikZ: {formatted_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103634d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load small_seg model for visualization\n",
    "from segmentation.small_seg import small_segmenter\n",
    "\n",
    "# Create model with same config as training\n",
    "seg_model = small_segmenter(\n",
    "    input_shape=(128, 128, 202, 1),\n",
    "    num_classes=4,\n",
    "    base_filters=8,\n",
    "    depth=3,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "# Build model with dummy input\n",
    "dummy_input = tf.random.normal([1, 128, 128, 202, 1])\n",
    "_ = seg_model(dummy_input, training=False)\n",
    "\n",
    "# Load best weights\n",
    "weights_path = \"./output/models/small_seg_best.weights.h5\"\n",
    "seg_model.load_weights(weights_path)\n",
    "print(f\"Model loaded from: {weights_path}\")\n",
    "\n",
    "# Display model summary\n",
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38859110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing segmentation predictions vs ground truth\n",
    "from TFDataloader.TFdataloader import TFHySpecNetLoader\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random\n",
    "\n",
    "# Create constant colormap: 0=Black - None, 1=Blue - Land, 2=Green - Water, 3=Red - Background\n",
    "class_colors = ['black', 'blue', 'green', 'red']\n",
    "constant_cmap = ListedColormap(class_colors)\n",
    "\n",
    "def visualize_segmentation_comparison(image, gt_mask, pred_mask, save_dir=None, sample_num=None):\n",
    "    \"\"\"Save images only if save_dir and sample_num provided. No display, no borders, no titles.\"\"\"\n",
    "    \n",
    "    if not (save_dir and sample_num):\n",
    "        return\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if os.path.exists(os.path.join(save_dir, f\"sample_{sample_num:02d}_input.png\")):\n",
    "        print(f\"Sample {sample_num:02d} already exists. Skipping...\")\n",
    "        return\n",
    "    # Input Image\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(hsi_to_rgb(image.numpy()))\n",
    "    ax.axis(\"off\")\n",
    "    input_path = os.path.join(save_dir, f\"sample_{sample_num:02d}_input.png\")\n",
    "    fig.savefig(input_path, dpi=150, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {input_path}\")\n",
    "    \n",
    "    # Ground Truth Mask\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(gt_mask, cmap=constant_cmap, vmin=0, vmax=3)\n",
    "    ax.axis(\"off\")\n",
    "    gt_path = os.path.join(save_dir, f\"sample_{sample_num:02d}_gt.png\")\n",
    "    fig.savefig(gt_path, dpi=150, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {gt_path}\")\n",
    "    \n",
    "    # Model Prediction\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(pred_mask, cmap=constant_cmap, vmin=0, vmax=3)\n",
    "    ax.axis(\"off\")\n",
    "    pred_path = os.path.join(save_dir, f\"sample_{sample_num:02d}_pred.png\")\n",
    "    fig.savefig(pred_path, dpi=150, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {pred_path}\")\n",
    "\n",
    "\n",
    "# Load test data\n",
    "data_loader = TFHySpecNetLoader(\n",
    "    \"./test_data/hyspecnet-11k/\",\n",
    "    batch_size=1, \n",
    "    data_mode=3, \n",
    "    split=\"test\"\n",
    ")\n",
    "data_set = data_loader._create_dataset(1000)\n",
    "\n",
    "# Convert dataset to list for random sampling\n",
    "print(\"Loading dataset samples...\")\n",
    "dataset_samples = []\n",
    "for images, masks in data_set:\n",
    "    # Only keep samples with multiple classes\n",
    "    counts = tf.unique(tf.reshape(masks[0], [-1])).y\n",
    "    if counts.shape[0] >= 2:\n",
    "        dataset_samples.append((images, masks))\n",
    "\n",
    "print(f\"Found {len(dataset_samples)} multi-class samples\")\n",
    "\n",
    "# Randomly select samples to visualize\n",
    "num_to_show = 40\n",
    "\n",
    "random_samples = random.sample(dataset_samples, min(num_to_show, len(dataset_samples)))\n",
    "\n",
    "for idx, (images, masks) in enumerate(random_samples):\n",
    "    image = images[0].numpy().squeeze()\n",
    "    image_reshuffled = tf.transpose(image, [0, 1, 2])\n",
    "    \n",
    "    # Run model prediction\n",
    "    pred_probs = seg_model(images, training=False)  # (1, 128, 128, 4)\n",
    "    pred_mask = tf.argmax(pred_probs[0], axis=-1).numpy()  # (128, 128)\n",
    "    gt_mask = masks[0].numpy()  # (128, 128)\n",
    "    \n",
    "    # Visualize comparison\n",
    "    counts = tf.unique(tf.reshape(masks[0], [-1])).y\n",
    "    print(f\"Sample {idx + 1} - Unique GT classes: {counts.numpy()}\")\n",
    "    visualize_segmentation_comparison(image_reshuffled, gt_mask, pred_mask,\n",
    "                                      save_dir=\"./Latex/graf\", sample_num=idx + 1)\n",
    "\n",
    "print(f\"\\nVisualizations complete. Showed {len(random_samples)} random samples.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
